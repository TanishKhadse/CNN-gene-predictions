{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch_geometric\n",
    "!pip install torch\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 45\n",
      "Package                    Version\n",
      "-------------------------- ----------\n",
      "absl-py                    1.4.0\n",
      "aiohttp                    3.9.1\n",
      "aiosignal                  1.3.1\n",
      "appnope                    0.1.3\n",
      "asttokens                  2.4.1\n",
      "astunparse                 1.6.3\n",
      "attrs                      23.1.0\n",
      "blinker                    1.6.2\n",
      "CacheControl               0.13.1\n",
      "cachetools                 5.3.1\n",
      "certifi                    2023.11.17\n",
      "cffi                       1.15.1\n",
      "charset-normalizer         3.1.0\n",
      "click                      8.1.3\n",
      "cloud-sql-python-connector 1.4.3\n",
      "cloudevents                1.9.0\n",
      "comm                       0.1.4\n",
      "contourpy                  1.2.0\n",
      "cryptography               41.0.1\n",
      "cycler                     0.12.1\n",
      "debugpy                    1.8.0\n",
      "decorator                  5.1.1\n",
      "deprecation                2.1.0\n",
      "executing                  2.0.1\n",
      "filelock                   3.13.1\n",
      "firebase-admin             6.2.0\n",
      "firebase-functions         0.1.0\n",
      "Flask                      3.0.0\n",
      "Flask-Cors                 4.0.0\n",
      "flatbuffers                23.5.26\n",
      "fonttools                  4.47.0\n",
      "frozenlist                 1.4.0\n",
      "fsspec                     2023.12.2\n",
      "functions-framework        3.4.0\n",
      "gast                       0.4.0\n",
      "google-api-core            2.11.1\n",
      "google-api-python-client   2.91.0\n",
      "google-auth                2.25.1\n",
      "google-auth-httplib2       0.1.0\n",
      "google-auth-oauthlib       1.0.0\n",
      "google-cloud-core          2.3.2\n",
      "google-cloud-firestore     2.11.1\n",
      "google-cloud-storage       2.13.0\n",
      "google-crc32c              1.5.0\n",
      "google-events              0.9.0\n",
      "google-pasta               0.2.0\n",
      "google-resumable-media     2.6.0\n",
      "googleapis-common-protos   1.59.1\n",
      "grpcio                     1.56.0\n",
      "grpcio-status              1.56.0\n",
      "gunicorn                   20.1.0\n",
      "h5py                       3.9.0\n",
      "httplib2                   0.22.0\n",
      "idna                       3.4\n",
      "indexed-gzip               1.7.1\n",
      "ipykernel                  6.26.0\n",
      "ipython                    8.17.2\n",
      "itsdangerous               2.1.2\n",
      "jedi                       0.19.1\n",
      "Jinja2                     3.1.2\n",
      "joblib                     1.3.2\n",
      "jupyter_client             8.5.0\n",
      "jupyter_core               5.5.0\n",
      "keras                      2.13.1\n",
      "kiwisolver                 1.4.5\n",
      "libclang                   16.0.0\n",
      "Markdown                   3.4.3\n",
      "MarkupSafe                 2.1.3\n",
      "matplotlib                 3.8.2\n",
      "matplotlib-inline          0.1.6\n",
      "mpmath                     1.3.0\n",
      "msgpack                    1.0.5\n",
      "multidict                  6.0.4\n",
      "nest-asyncio               1.5.8\n",
      "networkx                   3.2.1\n",
      "numpy                      1.24.3\n",
      "oauthlib                   3.2.2\n",
      "opt-einsum                 3.3.0\n",
      "packaging                  23.1\n",
      "pandas                     2.0.2\n",
      "parso                      0.8.3\n",
      "pexpect                    4.8.0\n",
      "pillow                     10.2.0\n",
      "pip                        23.3.2\n",
      "platformdirs               3.11.0\n",
      "prompt-toolkit             3.0.39\n",
      "proto-plus                 1.22.3\n",
      "protobuf                   4.23.3\n",
      "psutil                     5.9.6\n",
      "ptyprocess                 0.7.0\n",
      "pure-eval                  0.2.2\n",
      "pyasn1                     0.5.0\n",
      "pyasn1-modules             0.3.0\n",
      "pycparser                  2.21\n",
      "Pygments                   2.16.1\n",
      "PyJWT                      2.7.0\n",
      "PyMySQL                    1.1.0\n",
      "pyparsing                  3.1.0\n",
      "python-dateutil            2.8.2\n",
      "python-dotenv              1.0.0\n",
      "pytz                       2023.3\n",
      "PyYAML                     6.0\n",
      "pyzmq                      25.1.1\n",
      "requests                   2.31.0\n",
      "requests-oauthlib          1.3.1\n",
      "rsa                        4.9\n",
      "scikit-learn               1.3.2\n",
      "scipy                      1.11.4\n",
      "setuptools                 65.5.0\n",
      "six                        1.16.0\n",
      "SQLAlchemy                 2.0.23\n",
      "stack-data                 0.6.3\n",
      "sympy                      1.12\n",
      "tensorboard                2.13.0\n",
      "tensorboard-data-server    0.7.1\n",
      "tensorflow                 2.13.0\n",
      "tensorflow-estimator       2.13.0\n",
      "tensorflow-macos           2.13.0\n",
      "termcolor                  2.3.0\n",
      "threadpoolctl              3.2.0\n",
      "torch                      2.1.2\n",
      "torch_geometric            2.4.0\n",
      "tornado                    6.3.3\n",
      "tqdm                       4.66.1\n",
      "traitlets                  5.13.0\n",
      "typing_extensions          4.5.0\n",
      "tzdata                     2023.3\n",
      "uritemplate                4.1.1\n",
      "urllib3                    1.26.16\n",
      "watchdog                   3.0.0\n",
      "wcwidth                    0.2.9\n",
      "Werkzeug                   3.0.1\n",
      "wheel                      0.40.0\n",
      "wrapt                      1.15.0\n",
      "yarl                       1.9.3\n",
      "Requirement already satisfied: executing in /Users/tanishk/Library/Python/3.11/lib/python/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip list\n",
    "!pip install -U executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Dataset.get_summary of Cora()>\n",
      "8 8 8\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch_geometric.nn import GCNConv, SAGEConv, to_hetero\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, \n",
    "                      num_test=0.1, # uses 10% of data for test data set, rest is for training\n",
    "                      is_undirected=True, \n",
    "                      add_negative_train_samples=False)\n",
    "])\n",
    "\n",
    "# data\n",
    "dataset = Planetoid(root=\"testdata\", name=\"Cora\", transform=transform)\n",
    "\n",
    "\n",
    "# print(\"Data Info: \", dataset.name)\n",
    "# print(\"Number of graphs: \", len(dataset))\n",
    "# print(\"Number of features: \", dataset.num_features)\n",
    "# print(\"Number of classes (node types): \", dataset.num_classes)\n",
    "# print(\"Number of edge features: \", dataset.num_edge_features)\n",
    "# print(\"Number of node features: \", dataset.num_node_features )\n",
    "\n",
    "\n",
    "print(dataset.get_summary)\n",
    "\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "dataset[0]\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCNN Model Implementation\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    # forward pass (embeddings)\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "    \n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "\n",
    "model = Net(dataset.num_features, 128, 64)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index,\n",
    "        num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    edge_label = torch.cat(\n",
    "        [train_data.edge_label, train_data.edge_label.new_zeros(neg_edge_index.size(1))],\n",
    "        dim=0\n",
    "    )\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6930, Val: 0.6472, Test: 0.7210\n",
      "Epoch: 002, Loss: 0.6823, Val: 0.6366, Test: 0.7165\n",
      "Epoch: 003, Loss: 0.7088, Val: 0.6434, Test: 0.7220\n",
      "Epoch: 004, Loss: 0.6774, Val: 0.6642, Test: 0.7341\n",
      "Epoch: 005, Loss: 0.6849, Val: 0.6824, Test: 0.7420\n",
      "Epoch: 006, Loss: 0.6882, Val: 0.6964, Test: 0.7455\n",
      "Epoch: 007, Loss: 0.6890, Val: 0.6867, Test: 0.7383\n",
      "Epoch: 008, Loss: 0.6885, Val: 0.6675, Test: 0.7255\n",
      "Epoch: 009, Loss: 0.6864, Val: 0.6518, Test: 0.7155\n",
      "Epoch: 010, Loss: 0.6820, Val: 0.6390, Test: 0.7093\n",
      "Epoch: 011, Loss: 0.6759, Val: 0.6346, Test: 0.7055\n",
      "Epoch: 012, Loss: 0.6720, Val: 0.6305, Test: 0.7007\n",
      "Epoch: 013, Loss: 0.6753, Val: 0.6309, Test: 0.6952\n",
      "Epoch: 014, Loss: 0.6714, Val: 0.6375, Test: 0.6920\n",
      "Epoch: 015, Loss: 0.6621, Val: 0.6531, Test: 0.6959\n",
      "Epoch: 016, Loss: 0.6597, Val: 0.6727, Test: 0.7068\n",
      "Epoch: 017, Loss: 0.6567, Val: 0.6872, Test: 0.7165\n",
      "Epoch: 018, Loss: 0.6512, Val: 0.6902, Test: 0.7160\n",
      "Epoch: 019, Loss: 0.6434, Val: 0.6890, Test: 0.7134\n",
      "Epoch: 020, Loss: 0.6311, Val: 0.6920, Test: 0.7163\n",
      "Epoch: 021, Loss: 0.6254, Val: 0.7170, Test: 0.7323\n",
      "Epoch: 022, Loss: 0.6102, Val: 0.7509, Test: 0.7491\n",
      "Epoch: 023, Loss: 0.6006, Val: 0.7617, Test: 0.7523\n",
      "Epoch: 024, Loss: 0.5901, Val: 0.7607, Test: 0.7464\n",
      "Epoch: 025, Loss: 0.5756, Val: 0.7511, Test: 0.7366\n",
      "Epoch: 026, Loss: 0.5722, Val: 0.7574, Test: 0.7394\n",
      "Epoch: 027, Loss: 0.5665, Val: 0.7638, Test: 0.7423\n",
      "Epoch: 028, Loss: 0.5616, Val: 0.7670, Test: 0.7464\n",
      "Epoch: 029, Loss: 0.5558, Val: 0.7695, Test: 0.7524\n",
      "Epoch: 030, Loss: 0.5488, Val: 0.7761, Test: 0.7621\n",
      "Epoch: 031, Loss: 0.5487, Val: 0.7844, Test: 0.7720\n",
      "Epoch: 032, Loss: 0.5384, Val: 0.7934, Test: 0.7838\n",
      "Epoch: 033, Loss: 0.5282, Val: 0.8008, Test: 0.7952\n",
      "Epoch: 034, Loss: 0.5196, Val: 0.8089, Test: 0.8061\n",
      "Epoch: 035, Loss: 0.5182, Val: 0.8185, Test: 0.8175\n",
      "Epoch: 036, Loss: 0.5073, Val: 0.8191, Test: 0.8227\n",
      "Epoch: 037, Loss: 0.5133, Val: 0.8219, Test: 0.8292\n",
      "Epoch: 038, Loss: 0.5050, Val: 0.8248, Test: 0.8353\n",
      "Epoch: 039, Loss: 0.5027, Val: 0.8297, Test: 0.8411\n",
      "Epoch: 040, Loss: 0.5105, Val: 0.8335, Test: 0.8473\n",
      "Epoch: 041, Loss: 0.5013, Val: 0.8363, Test: 0.8527\n",
      "Epoch: 042, Loss: 0.4969, Val: 0.8436, Test: 0.8594\n",
      "Epoch: 043, Loss: 0.4897, Val: 0.8516, Test: 0.8664\n",
      "Epoch: 044, Loss: 0.4832, Val: 0.8556, Test: 0.8712\n",
      "Epoch: 045, Loss: 0.4866, Val: 0.8577, Test: 0.8741\n",
      "Epoch: 046, Loss: 0.4809, Val: 0.8575, Test: 0.8744\n",
      "Epoch: 047, Loss: 0.4747, Val: 0.8587, Test: 0.8756\n",
      "Epoch: 048, Loss: 0.4754, Val: 0.8580, Test: 0.8774\n",
      "Epoch: 049, Loss: 0.4852, Val: 0.8582, Test: 0.8793\n",
      "Epoch: 050, Loss: 0.4804, Val: 0.8579, Test: 0.8805\n",
      "Epoch: 051, Loss: 0.4772, Val: 0.8580, Test: 0.8822\n",
      "Epoch: 052, Loss: 0.4833, Val: 0.8583, Test: 0.8829\n",
      "Epoch: 053, Loss: 0.4706, Val: 0.8586, Test: 0.8850\n",
      "Epoch: 054, Loss: 0.4748, Val: 0.8592, Test: 0.8881\n",
      "Epoch: 055, Loss: 0.4659, Val: 0.8605, Test: 0.8896\n",
      "Epoch: 056, Loss: 0.4664, Val: 0.8642, Test: 0.8912\n",
      "Epoch: 057, Loss: 0.4599, Val: 0.8673, Test: 0.8926\n",
      "Epoch: 058, Loss: 0.4679, Val: 0.8678, Test: 0.8943\n",
      "Epoch: 059, Loss: 0.4645, Val: 0.8668, Test: 0.8954\n",
      "Epoch: 060, Loss: 0.4631, Val: 0.8693, Test: 0.8966\n",
      "Epoch: 061, Loss: 0.4639, Val: 0.8725, Test: 0.8974\n",
      "Epoch: 062, Loss: 0.4617, Val: 0.8744, Test: 0.8985\n",
      "Epoch: 063, Loss: 0.4631, Val: 0.8760, Test: 0.9001\n",
      "Epoch: 064, Loss: 0.4650, Val: 0.8773, Test: 0.9024\n",
      "Epoch: 065, Loss: 0.4546, Val: 0.8778, Test: 0.9035\n",
      "Epoch: 066, Loss: 0.4640, Val: 0.8774, Test: 0.9038\n",
      "Epoch: 067, Loss: 0.4561, Val: 0.8794, Test: 0.9058\n",
      "Epoch: 068, Loss: 0.4565, Val: 0.8808, Test: 0.9078\n",
      "Epoch: 069, Loss: 0.4539, Val: 0.8820, Test: 0.9089\n",
      "Epoch: 070, Loss: 0.4574, Val: 0.8823, Test: 0.9098\n",
      "Epoch: 071, Loss: 0.4547, Val: 0.8809, Test: 0.9098\n",
      "Epoch: 072, Loss: 0.4607, Val: 0.8800, Test: 0.9104\n",
      "Epoch: 073, Loss: 0.4650, Val: 0.8809, Test: 0.9117\n",
      "Epoch: 074, Loss: 0.4476, Val: 0.8825, Test: 0.9128\n",
      "Epoch: 075, Loss: 0.4476, Val: 0.8832, Test: 0.9131\n",
      "Epoch: 076, Loss: 0.4562, Val: 0.8825, Test: 0.9121\n",
      "Epoch: 077, Loss: 0.4504, Val: 0.8823, Test: 0.9119\n",
      "Epoch: 078, Loss: 0.4502, Val: 0.8824, Test: 0.9123\n",
      "Epoch: 079, Loss: 0.4467, Val: 0.8840, Test: 0.9125\n",
      "Epoch: 080, Loss: 0.4514, Val: 0.8850, Test: 0.9126\n",
      "Epoch: 081, Loss: 0.4552, Val: 0.8854, Test: 0.9124\n",
      "Epoch: 082, Loss: 0.4382, Val: 0.8863, Test: 0.9130\n",
      "Epoch: 083, Loss: 0.4469, Val: 0.8864, Test: 0.9139\n",
      "Epoch: 084, Loss: 0.4518, Val: 0.8870, Test: 0.9145\n",
      "Epoch: 085, Loss: 0.4469, Val: 0.8881, Test: 0.9140\n",
      "Epoch: 086, Loss: 0.4405, Val: 0.8883, Test: 0.9138\n",
      "Epoch: 087, Loss: 0.4454, Val: 0.8891, Test: 0.9152\n",
      "Epoch: 088, Loss: 0.4465, Val: 0.8893, Test: 0.9173\n",
      "Epoch: 089, Loss: 0.4523, Val: 0.8896, Test: 0.9181\n",
      "Epoch: 090, Loss: 0.4447, Val: 0.8906, Test: 0.9186\n",
      "Epoch: 091, Loss: 0.4436, Val: 0.8914, Test: 0.9184\n",
      "Epoch: 092, Loss: 0.4362, Val: 0.8915, Test: 0.9190\n",
      "Epoch: 093, Loss: 0.4394, Val: 0.8920, Test: 0.9208\n",
      "Epoch: 094, Loss: 0.4409, Val: 0.8912, Test: 0.9223\n",
      "Epoch: 095, Loss: 0.4365, Val: 0.8910, Test: 0.9227\n",
      "Epoch: 096, Loss: 0.4401, Val: 0.8912, Test: 0.9224\n",
      "Epoch: 097, Loss: 0.4338, Val: 0.8917, Test: 0.9230\n",
      "Epoch: 098, Loss: 0.4338, Val: 0.8917, Test: 0.9243\n",
      "Epoch: 099, Loss: 0.4344, Val: 0.8922, Test: 0.9247\n",
      "Epoch: 100, Loss: 0.4402, Val: 0.8913, Test: 0.9239\n",
      "Final Test: 0.9247\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1,101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, ' f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [   0,    2,    4,  ..., 2705, 2706, 2707]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built own dataset\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "import torch_geometric.data as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# make a graph with 100 nodes, and 16 dimensions per node (node features)\n",
    "# randomizes feature vectors with values (0-1)\n",
    "nodes = torch.rand((100, 16), dtype=torch.float) \n",
    "\n",
    "\n",
    "# randomly sample indexes of 100 nodes and creates 500 edges\n",
    "rows = np.random.choice(100, 250)\n",
    "cols = np.random.choice(100, 250)\n",
    "edges = torch.tensor([rows, cols])\n",
    "\n",
    "# randomly adds 500 edge attributes between 0 and 3 (a random attribute for each edge)\n",
    "edges_attr = np.random.choice(3,250)\n",
    "\n",
    "# generates 100 0's or 1's (for nodes), long means categotical data\n",
    "ys = torch.rand((100)).round().long()\n",
    "\n",
    "\n",
    "# Convert graph information to PyG data object:\n",
    "'''\n",
    "Data(x, edge_index, edges_attr, y)\n",
    "\n",
    "    x ~ Node feature matrix --> [num_nodes x num_node_features]\n",
    "\n",
    "    edge_index ~ Graph connectivity in COO format with shape [2, num_edges]\n",
    "\n",
    "    edges_attr ~ similar to x but for edges; [num_edges, num_edge_features]\n",
    "\n",
    "    y ~ Graph level or node level ground-truth labels with arbitrary shape; node_labels\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "graph = dt.HeteroData(x=nodes, edge_index=edges, edges_attr=edges_attr, y=ys)\n",
    "\n",
    "# vis = to_networkx(graph)\n",
    "# node_labels = graph.y.numpy()\n",
    "# plt.figure(1, figsize=(15, 13))\n",
    "# nx.draw(vis, cmap=plt.get_cmap('Set3'), node_color=node_labels, node_size=70, linewidths=6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneGene data:  (733836,)\n",
      "GeneGene ir:  (733836,)\n",
      "GeneGene jc:  (12332,)\n",
      "Gene Features:  (4536, 12331)\n",
      "Clinical Features:  (16592, 3215)\n",
      "GeneIds:  (1, 12331)\n",
      "PheneIds:  (9, 1)\n",
      "[2.00000e+00 5.00000e+00 1.00100e+05 ... 1.61550e+05 6.10805e+05\n",
      " 6.14485e+05]\n",
      "GenePhenes:  (9, 1)\n",
      "12332\n",
      "(12331, 12331)\n",
      "(3215, 3215)\n",
      "(12331, 3215)\n"
     ]
    }
   ],
   "source": [
    "# Load data from .mat files\n",
    "\n",
    "gf_data = h5py.File(\"../data/GeneFeatures.mat\", 'r')\n",
    "gp_data= h5py.File(\"../data/genes_phenes.mat\", 'r')\n",
    "cf_data = h5py.File(\"../data/clinicalfeatures_tfidf.mat\", 'r')\n",
    "\n",
    "# print(cf_data.keys())\n",
    "\n",
    "gene_ids = gp_data[\"geneIds\"]\n",
    "phene_ids = gp_data[\"pheneIds\"]\n",
    "\n",
    "# GeneGene_Hs --> \"data\", \"ir\", \"jc\"\n",
    "print(\"GeneGene data: \", gp_data[\"GeneGene_Hs\"][\"data\"].shape)\n",
    "print(\"GeneGene ir: \", gp_data[\"GeneGene_Hs\"][\"ir\"].shape)\n",
    "print(\"GeneGene jc: \", gp_data[\"GeneGene_Hs\"][\"jc\"].shape)\n",
    "print(\"Gene Features: \", gf_data[\"GeneFeatures\"].shape) # 4536x12331\n",
    "print(\"Clinical Features: \", cf_data[\"F\"].shape) # 3215\n",
    "print(\"GeneIds: \", gp_data[\"geneIds\"].shape)\n",
    "print(\"PheneIds: \", gp_data[\"pheneIds\"].shape)\n",
    "print(gp_data[gp_data[\"pheneIds\"][0][0]][0]) # 1x3215\n",
    "print(\"GenePhenes: \", gp_data[\"GenePhene\"].shape)\n",
    "\n",
    "\n",
    "gene_network_adj = sp.csc_matrix((np.array(gp_data['GeneGene_Hs']['data']),\n",
    "    np.array(gp_data['GeneGene_Hs']['ir']), np.array(gp_data['GeneGene_Hs']['jc'])),\n",
    "    shape=(12331,12331)).tocoo()\n",
    "\n",
    "disease_network_adj = sp.csc_matrix((np.array(gp_data['PhenotypeSimilarities']['data']),\n",
    "    np.array(gp_data['PhenotypeSimilarities']['ir']), np.array(gp_data['PhenotypeSimilarities']['jc'])),\n",
    "    shape=(3215, 3215)).tocoo()\n",
    "\n",
    "disease_offset = gene_network_adj.shape[0]+1\n",
    "\n",
    "\n",
    "dg_ref = gp_data['GenePhene'][0][0]\n",
    "gene_disease_adj = sp.csc_matrix((np.array(gp_data[dg_ref]['data']),\n",
    "    np.array(gp_data[dg_ref]['ir']), np.array(gp_data[dg_ref]['jc'])),\n",
    "    shape=(12331, 3215)).tocoo()\n",
    "\n",
    "print(disease_offset)\n",
    "\n",
    "\n",
    "print(gene_network_adj.shape)   # which genes are linked to each other\n",
    "print(disease_network_adj.shape) # which diseases are linked to each other\n",
    "print(gene_disease_adj.shape) # which genes are linked to which diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up Gene Features into a tensor\n",
    "gene_nodes = torch.tensor(gf_data[\"GeneFeatures\"][:]).T\n",
    "disease_nodes = torch.tensor(cf_data[\"F\"][:]).T\n",
    "\n",
    "gene_rows = gene_network_adj.row\n",
    "gene_cols = gene_network_adj.col\n",
    "gene_data = gene_network_adj.data\n",
    "\n",
    "disease_rows = disease_network_adj.row\n",
    "disease_cols = disease_network_adj.col\n",
    "disease_data = disease_network_adj.data\n",
    "\n",
    "gene_disease_rows = gene_disease_adj.row\n",
    "gene_disease_cols =  gene_disease_adj.col\n",
    "gene_disease_data = gene_disease_adj.data\n",
    "\n",
    "\n",
    "\n",
    "gm_graph = dt.HeteroData()\n",
    "gm_graph[\"gene\"].x = gene_nodes\n",
    "\n",
    "gm_graph[\"gene\", \"gene_gene\", \"gene\"].edge_index = torch.tensor([gene_rows, gene_cols])\n",
    "gm_graph[\"gene\", \"gene_gene\", \"gene\"].edge_attr = torch.tensor(gene_data)\n",
    "\n",
    "gm_graph[\"disease\"].x = disease_nodes\n",
    "gm_graph[\"disease\", \"dis_dis\", \"disease\"].edge_index = torch.tensor([disease_rows, disease_cols])\n",
    "gm_graph[\"disease\", \"dis_dis\", \"disease\"].edge_attr = torch.tensor(disease_data)\n",
    "\n",
    "gm_graph[\"gene\", \"gda\", \"disease\"].edge_index = torch.tensor([gene_disease_rows, gene_disease_cols])\n",
    "gm_graph[\"gene\", \"gda\", \"disease\"].edge_attr = torch.tensor(gene_disease_data)\n",
    "\n",
    "\n",
    "\n",
    "# gm_graph.add_edge_index(edge_index=[gene_rows, gene_cols], edge_attr=gene_data, source=\"gene\", target=\"gene\")\n",
    "# gm_graph.add_edge_index(edge_index=[disease_rows, disease_cols], edge_attr=disease_data, source=\"disease\", target=\"disease\")\n",
    "# gm_graph.add_edge_index(edge_index=[gene_disease_rows, gene_disease_cols], edge_attr=gene_disease_data, source=\"gene\", target=\"disease\")\n",
    "\n",
    "\n",
    "gene_mutations = [gm_graph]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "gm_graph.num_nodes\n",
    "print(len(gm_graph.num_node_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  gene={ x=[12331, 4536] },\n",
      "  disease={ x=[3215, 16592] },\n",
      "  (gene, gene_gene, gene)={\n",
      "    edge_index=[2, 623764],\n",
      "    edge_attr=[623764],\n",
      "    edge_label=[311882],\n",
      "    edge_label_index=[2, 311882],\n",
      "  },\n",
      "  (disease, dis_dis, disease)={\n",
      "    edge_index=[2, 2704872],\n",
      "    edge_attr=[2704872],\n",
      "    edge_label=[1352436],\n",
      "    edge_label_index=[2, 1352436],\n",
      "  },\n",
      "  (gene, gda, disease)={\n",
      "    edge_index=[2, 3362],\n",
      "    edge_attr=[3362],\n",
      "    edge_label=[3362],\n",
      "    edge_label_index=[2, 3362],\n",
      "  },\n",
      "  (disease, rev_gda, gene)={\n",
      "    edge_index=[2, 3954],\n",
      "    edge_attr=[3954],\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  gene={ x=[12331, 4536] },\n",
      "  disease={ x=[3215, 16592] },\n",
      "  (gene, gene_gene, gene)={\n",
      "    edge_index=[2, 623764],\n",
      "    edge_attr=[623764],\n",
      "    edge_label=[55035],\n",
      "    edge_label_index=[2, 55035],\n",
      "  },\n",
      "  (disease, dis_dis, disease)={\n",
      "    edge_index=[2, 2704872],\n",
      "    edge_attr=[2704872],\n",
      "    edge_label=[238662],\n",
      "    edge_label_index=[2, 238662],\n",
      "  },\n",
      "  (gene, gda, disease)={\n",
      "    edge_index=[2, 3362],\n",
      "    edge_attr=[3362],\n",
      "    edge_label=[591],\n",
      "    edge_label_index=[2, 591],\n",
      "  },\n",
      "  (disease, rev_gda, gene)={\n",
      "    edge_index=[2, 3954],\n",
      "    edge_attr=[3954],\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  gene={ x=[12331, 4536] },\n",
      "  disease={ x=[3215, 16592] },\n",
      "  (gene, gene_gene, gene)={\n",
      "    edge_index=[2, 660454],\n",
      "    edge_attr=[660454],\n",
      "    edge_label=[110073],\n",
      "    edge_label_index=[2, 110073],\n",
      "  },\n",
      "  (disease, dis_dis, disease)={\n",
      "    edge_index=[2, 2863980],\n",
      "    edge_attr=[2863980],\n",
      "    edge_label=[477327],\n",
      "    edge_label_index=[2, 477327],\n",
      "  },\n",
      "  (gene, gda, disease)={\n",
      "    edge_index=[2, 3559],\n",
      "    edge_attr=[3559],\n",
      "    edge_label=[1185],\n",
      "    edge_label_index=[2, 1185],\n",
      "  },\n",
      "  (disease, rev_gda, gene)={\n",
      "    edge_index=[2, 3954],\n",
      "    edge_attr=[3954],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "class GeneMutations(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, data_list=None):\n",
    "        super(GeneMutations, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "\n",
    "# transform = T.Compose([\n",
    "#     T.NormalizeFeatures(),\n",
    "#     T.ToDevice(device),\n",
    "#     T.RandomLinkSplit(num_val=0.05, \n",
    "#                       num_test=0.1, # uses 10% of data for test data set, rest is for training\n",
    "#                       is_undirected=True,  \n",
    "#                       add_negative_train_samples=False,\n",
    "#                       edge_types=gm_graph.edge_types)\n",
    "# ])\n",
    "\n",
    "transform = T.Compose([\n",
    "        T.ToUndirected(),\n",
    "        T.RandomLinkSplit(\n",
    "            num_val=0.05,\n",
    "            num_test=0.1,\n",
    "            is_undirected=True,\n",
    "            neg_sampling_ratio=2.0,\n",
    "            edge_types=gm_graph.edge_types,\n",
    "            # rev_edge_types=(\"disease\", \"gda\", \"gene\"),\n",
    "            add_negative_train_samples=False\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "gm = GeneMutations(\".\", transform=transform, data_list=gene_mutations)\n",
    "train_data, val_data, test_data = gm[0]\n",
    "\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    }
   ],
   "source": [
    "# model = Net(graph.num_features, 128, 64)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels=0):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), hidden_channels) # out_channels\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def decode(self, x_gene, x_disease, edge_label_index):\n",
    "        edge_feat_gene = x_gene[edge_label_index[0]]\n",
    "        edge_feat_disease = x_disease[edge_label_index[1]]\n",
    "        return (edge_feat_gene * edge_feat_disease).sum(dim=-1)\n",
    "\n",
    "    \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(20, hidden_channels)\n",
    "        self.gene_emb = torch.nn.Embedding(gm_graph[\"gene\"].num_nodes, hidden_channels)\n",
    "        self.disease_emb = torch.nn.Embedding(gm_graph[\"disease\"].num_nodes, hidden_channels)\n",
    "\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        self.gnn = to_hetero(self.gnn, metadata=gm_graph.metadata())\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def decode_all(self, data):\n",
    "        x_dict = {\n",
    "            \"gene\": self.gene_emb(data[\"gene\"].node_id),\n",
    "            \"disease\": self.disease_emb(data[\"disease\".node_id])\n",
    "        }\n",
    "\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"gene\"],\n",
    "            x_dict[\"disease\"],\n",
    "            data[\"gene\", \"gda\", \"disease\"].edge_label_index\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "# model = GNN(hidden_channels=64, out_channels=len(gm_graph.num_node_features))\n",
    "model = Model(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index,\n",
    "        num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    edge_label = torch.cat(\n",
    "        [train_data.edge_label, train_data.edge_label.new_zeros(neg_edge_index.size(1))],\n",
    "        dim=0\n",
    "    )\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1,101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, ' f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
